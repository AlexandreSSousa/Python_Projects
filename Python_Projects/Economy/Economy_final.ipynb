{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas.\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import statsmodels.api as sm\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar o ficheiro que contém a informação dos países presentes na base de dados, e que contém 2 colunas que serão utilizadas no decorrer do trabalho (Region e IncomeGroup).\n",
    "metadata = pd.read_csv('Metadata_Country_API_SE.XPD.TOTL.GD.ZS_DS2_en_csv_v2_511370.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a  quantidade de linhas e colunas.\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o ficheiro metadata, de modo a reter as colunas pretendidas.\n",
    "dataframe = metadata.iloc[:,0:3]\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma lista com todos os ficheiros CSV a serem considerados na análise. Os ficheiros devem estar guardados na mesma pasta que o Jupyter Notebook.\n",
    "\n",
    "inputfiles = [f for f in listdir(os.getcwd()) if (f.endswith(\".csv\") and f.startswith(\"A\")) if isfile(join(os.getcwd(), f))]\n",
    "\n",
    "# Iniciar as variáveis em que os DataFrames serão armazenados.\n",
    "\n",
    "df0, df1=[0]*len(inputfiles), [0]*len(inputfiles)\n",
    "\n",
    "# Deixar o utilizador decidir o ano para o qual a análise será realizada.\n",
    "\n",
    "user_yr=int(input(\"Qual é o ano que deseja analisar? \"))\n",
    "\n",
    "#Loop\n",
    "for f in inputfiles:\n",
    "    # Ler o conteúdo dos ficheiros na lista df0.\n",
    "    df0[inputfiles.index(f)]=pd.read_csv(f, skiprows=4)\n",
    "    # Os ficheiros contêm dados que duram quase 60 anos. A variável seguinte determina a coluna, do ficheiro, que possui os dados correspondentes ao ano escolhido.\n",
    "    i_yr=user_yr-1960-(len(df0[inputfiles.index(f)].columns)-4)\n",
    "    # Criar um novo DataFrame com as colunas relevantes para a análise - mantivemos o código do país (para poder encontrar uma correspondência entre todos os dicheiros) e o nome de cada indicador (para nomear a coluna correta e automaticamente).\n",
    "    df1[inputfiles.index(f)] = df0[inputfiles.index(f)].iloc[:,[1,2,i_yr]]\n",
    "    # Renomear a coluna que contêm a data, em df1, pelo indicador.\n",
    "    df1[inputfiles.index(f)] = df1[inputfiles.index(f)].rename(columns={df1[inputfiles.index(f)].columns[2]: df1[inputfiles.index(f)].iloc[0,1]})\n",
    "    # Eliminar a coluna cujo nome é \"Indicator\".\n",
    "    df1[inputfiles.index(f)] = df1[inputfiles.index(f)].loc[:, ~df1[inputfiles.index(f)].columns.str.startswith('Indicator')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar todos os dados, para o ano escolhido, num único DataFrame. Esta ação é feita através da variável \"Country Code\" para que exista uma correnpondência entre todos os ficheiros.\n",
    "df=df1[0]\n",
    "for i in range(1,len(df1)):\n",
    "    df=pd.merge(df1[i], df, how='left',left_on='Country Code', right_on='Country Code')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a quantidade de linhas e colunas para o ano escolhido.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar um país, neste caso, França. \n",
    "df.loc[df['Country Code'] == \"FRA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar a estrutura da tabela de objetos (left): Country Name, Country Code, Region, IncomeGroup.\n",
    "dataframe = pd.merge(dataframe,df, how='left',left_on='Country Code', right_on='Country Code')\n",
    "dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar as linhas que contêm erros, ou dados omissos, nalguma das variáveis.\n",
    "dataframe=dataframe.dropna()\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a quantidade de linhas e colunas, após a eliminação das linhas.\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizar os ultimos registos.\n",
    "dataframe.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renumerar o indice do dataframe.\n",
    "dataframe = dataframe.reset_index(drop=True)\n",
    "dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o tipo das variáveis presente no dataframe.\n",
    "dataframe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar a correlação entre as variáveis presentes no dataframe.\n",
    "fig = plt.figure(figsize=[8, 8])\n",
    "corr_mtx = dataframe.corr()\n",
    "sns.heatmap(corr_mtx, xticklabels=corr_mtx.columns, yticklabels=corr_mtx.columns, annot=True, cmap='Blues')\n",
    "plt.title('Correlation analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar variáveis indejadas, caso existam, devido à elevada correlação. Responder \"Não\" caso não deseje executar uma eliminação e \"Sim\" no caso de desejar.\n",
    "a=input(\"Gostaria de eliminar alguma variável do dataframe? \")\n",
    "if a==\"Não\":\n",
    "    print(\"OK!\")\n",
    "elif a==\"Sim\":\n",
    "    b=input(\"Qual é o nome da coluna que deseja eliminar? \")\n",
    "    dataframe1=dataframe.drop(b,axis=1)\n",
    "    dataframe1.head()\n",
    "else:\n",
    "    print(\"Tente outra vez!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a variável dependente.\n",
    "Y = dataframe.loc[:,'GDP per capita (current US$)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as variáveis explicativas.\n",
    "X = dataframe.drop(['Country Code','Region', 'IncomeGroup', 'GDP per capita (current US$)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresão em que a variável dependente é \"GDP per capita (current US$)\" e as restantes variáveis são as explicativas.\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y,X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar scatterplot para a relação entre o GDP per capita e a variável com um maior impacto.\n",
    "i=input(\"Qual é a variável com maior coeficente? \")\n",
    "ydata = Y\n",
    "xdata = X.loc[:,i]\n",
    "colors = (0,0,0)\n",
    "area = np.pi*3\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.scatter(\n",
    "    xdata, \n",
    "    ydata, \n",
    "    s = area, \n",
    "    c = colors, \n",
    "    alpha = 1)\n",
    "\n",
    "for label, x, y in zip(dataframe.iloc[:,0], xdata, ydata):\n",
    "    plt.annotate(\n",
    "        label,\n",
    "        xy=(x, y), xytext=(2, 0),\n",
    "        textcoords = 'offset points', ha = 'left', va = 'bottom',\n",
    "        #bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        #arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0')\n",
    "    )\n",
    "    \n",
    "\n",
    "plt.title('Scatter plot')\n",
    "plt.xlabel(i)\n",
    "plt.ylabel('GDP per capita (current US$)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar uma scatter matrix para analisar a relação, dois a dois, das variáveis.\n",
    "stats = dataframe1.columns[3:]\n",
    "corr = dataframe1[stats].corr() # corr é utilizado para encontrar a correlação.\n",
    "color_function = {0: 'blue', 1: 'red'}\n",
    "colors = dataframe1['GDP per capita (current US$)'].map(lambda x: color_function.get(x))\n",
    "scatter_matrix(dataframe1[stats], alpha = 1, figsize = (25, 25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o dataframe para ficar apenas com os valores e os índices.\n",
    "dataframe2 = dataframe.iloc[:,3:]\n",
    "dataframe2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o Metodo Elbow para encontrar o número de clusters a considerar na análise.\n",
    "wcss = []\n",
    "for i in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=3000, n_init=10, random_state=0)\n",
    "    kmeans.fit(dataframe2)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 10), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o número de clusters que serão considerdados na análise.\n",
    "clus_num = int(input(\"De acordo com o método Elbow, quantos Clusters quer considerar na sua análise? \"))\n",
    "kmeans = KMeans(n_clusters = clus_num).fit(dataframe2)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = kmeans.predict(dataframe2)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o dataframe com os grupos (Clusters).\n",
    "groups = pd.DataFrame(pred_y, columns = ['Group'])\n",
    "groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar a coluna que contém o grupo do país ao dataframe inicial.\n",
    "dataframe = dataframe.merge(groups,left_index=True, right_index=True)\n",
    "dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir o gráfico com a contabilização de quantos países pertencem a cada grupo, por região.\n",
    "sns.countplot(y='Region', hue = 'Group', data = dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um novo data frame para a Decision Tree.\n",
    "ndataframe = ['Foreign direct investment, net inflows (% of GDP)','Gross savings (% of GDP)','Expense (% of GDP)','GDP per capita (current US$)','Exports of goods and services (% of GDP)','Inflation, consumer prices (annual %)']\n",
    "# Separar por variaveis.\n",
    "nx = dataframe.loc[:,ndataframe].values\n",
    "# Separar o alvo de estudo.\n",
    "ny = dataframe.loc[:,['IncomeGroup']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir o dataframe entre treino e teste.\n",
    "nx_train, nx_test, ny_train, ny_test = train_test_split(nx, ny, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o objeto da Decision Tree Classifer.\n",
    "clf = DecisionTreeClassifier()\n",
    "# Treinar Decision Tree Classifer.\n",
    "clf = clf.fit(nx_train,ny_train)\n",
    "# Prever a resposta para o dataframe de teste.\n",
    "y_pred1 = clf.predict(nx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar a taxa de precisão do modelo.\n",
    "print(\"A taxa de precisão do modelo é de:\",metrics.accuracy_score(ny_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o arquivo com a Decision Tree.\n",
    "import pydotplus\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file = dot_data, filled = True, rounded = True,\n",
    "                special_characters = True, feature_names = ndataframe)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('IncomeGroupDT.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
